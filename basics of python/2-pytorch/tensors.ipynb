{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "[Torch docs on tensors](https://pytorch.org/docs/stable/tensors.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors  \n",
    "From a python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2 , 3],[4 , 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([[[1,2],[2,3],[4,5]]])\n",
    "t = torch.tensor(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0716, 0.0323, 0.7047],\n",
       "         [0.2545, 0.3994, 0.2122],\n",
       "         [0.4089, 0.1481, 0.1733]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(1,3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Torch docs on how to create tensors](https://pytorch.org/docs/stable/torch.html#tensor-creation-ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor attributes\n",
    "[Docs on tensor attributes](https://pytorch.org/docs/stable/tensor_attributes.html#tensor-attributes-doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([[[1,2],[2,3],[4,5]]])\n",
    "t = torch.tensor(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions is 3\n",
      "Shape is torch.Size([1, 3, 2])\n",
      "cpu\n",
      "Datatype is torch.int64\n",
      "tensor([[[1., 2.],\n",
      "         [2., 3.],\n",
      "         [4., 5.]]])\n",
      "Number of elements is 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of dimensions is {t.ndim}\")\n",
    "print(f\"Shape is {t.shape}\") #1 dimension of 3x2 matrices (always from out to in and row first)\n",
    "print(t.device)\n",
    "print(f\"Datatype is {t.dtype}\") #float64 is default in numpy\n",
    "t = t.type(torch.float32) #changing datatype of the tensor into float32\n",
    "print(t) #the datatype is not printed because float32 is default in pytorch\n",
    "print(f\"Number of elements is {t.numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a linear transformation to the incoming data:  $ y = x A^T + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3])\n",
      "\n",
      "Output:tensor([[1.6293, 0.8116, 3.5593, 1.5407],\n",
      "        [2.4146, 1.3319, 4.1262, 1.7270]], grad_fn=<AddmmBackward0>)\n",
      "Output shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]], dtype=torch.float32)\n",
    "# Since the linear layer starts with a random weights matrix A, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "x = x.T\n",
    "linear = torch.nn.Linear(in_features=3, # in_features = matches inner dimension of input (second index of x, aka its columns)\n",
    "                         out_features=4, # out_features = describes outer value (second index of A, aka its columns)\n",
    "                         bias = True)\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:{output}\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Maximum 90 at index 9\n",
      "Minimum 0 at index 0\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(0, 100, 10)\n",
    "print(v)\n",
    "print(f\"Maximum {torch.max(v)} at index {torch.argmax(v)}\")\n",
    "print(f\"Minimum {torch.min(v)} at index {torch.argmin(v)}\")\n",
    "print(f\"Mean: {torch.mean(v.type(torch.float32))}\")\n",
    "print(f\"Sum: {torch.sum(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8823)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "v = torch.rand(2,3,3)\n",
    "v\n",
    "v[-2] #negative indices go from last to first element\n",
    "#putting only one index means taking only the first dimension\n",
    "v[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1332, 0.9346, 0.5936],\n",
       "         [0.8694, 0.5677, 0.7411],\n",
       "         [0.4294, 0.8854, 0.5739]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1:3] # is the same as line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1332, 0.9346, 0.5936],\n",
       "         [0.8694, 0.5677, 0.7411],\n",
       "         [0.4294, 0.8854, 0.5739]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8823, 0.9150, 0.3829],\n",
       "         [0.9593, 0.3904, 0.6009],\n",
       "         [1.0000, 2.0000, 3.0000]],\n",
       "\n",
       "        [[0.1332, 0.9346, 0.5936],\n",
       "         [0.8694, 0.5677, 0.7411],\n",
       "         [1.0000, 2.0000, 3.0000]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0:3,2] = torch.tensor([1,2,3])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the shape of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(0,12,1,dtype=torch.float32)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze and unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = v.unsqueeze(dim=0) #adds a \"dummy\" (=1) dimension at dim index\n",
    "print(v1)\n",
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = v1.squeeze(dim=0) #removes a \"dummy\" (=1) dimension at dim index\n",
    "print(v1)\n",
    "v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.]],\n",
       " \n",
       "         [[ 6.,  7.,  8.,  9., 10., 11.]]]),\n",
       " torch.Size([2, 1, 6]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape can't change numel, which means that the product of dimensions must be invariant\n",
    "#for that reason, one dimension can be -1 because python will do the rest \n",
    "v1 = v.reshape([2,1,-1])\n",
    "v1,v1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack\n",
    "- Puts on top of each other the tensors, creating a new dimension in position dim which will correspond to the number of stacked tensors\n",
    "- The other dimensions are the ones already present in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack([v,v],dim=0)\n",
    "print(stacked)\n",
    "stacked.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat\n",
    "- Concatenates tensor along the same dimension, without creating a new one (like stack)\n",
    "- If in the first example below we would choose dim = 1, an error would rise (v has just one dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.,  0.,  1.,\n",
      "         2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([24])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated = torch.cat([v,v],dim=0)\n",
    "print(concatenated)\n",
    "concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7886],\n",
      "        [0.5895]])\n",
      "tensor([[0.7539],\n",
      "        [0.1952]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.7886],\n",
       "        [0.5895]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.rand((2,1))\n",
    "print(v1)\n",
    "v2 = torch.rand((2,1))\n",
    "print(v2)\n",
    "torch.cat((v1,v2),dim = 1)\n",
    "torch.cat((torch.zeros(1,1),v1),dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting\n",
    "\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimension and works its way left. Two dimensions are compatible when\n",
    "- they are equal\n",
    "- one of them is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[ 0.3930,  0.4327],\n",
      "        [-1.3627,  1.3564],\n",
      "        [ 0.6688, -0.7077]], requires_grad=True) \n",
      "\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3930,  1.4327, -0.3627,  2.3564,  1.6688,  0.2923],\n",
       "        [ 1.3930,  1.4327, -0.3627,  2.3564,  1.6688,  0.2923],\n",
       "        [ 1.3930,  1.4327, -0.3627,  2.3564,  1.6688,  0.2923],\n",
       "        [ 1.3930,  1.4327, -0.3627,  2.3564,  1.6688,  0.2923]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3, 2), requires_grad=True)\n",
    "print(f\"x = {x} \\n\")\n",
    "y = x.reshape((1, 6))\n",
    "z = torch.ones((4, 1))\n",
    "print(z)\n",
    "(y + z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
