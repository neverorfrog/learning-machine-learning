{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does it mean to learn?\n",
    "\n",
    "\n",
    "## Intuitively\n",
    "\n",
    "### Generalization\n",
    "\n",
    "Take for example a student which has to answer some questions on a test. Generalizing means that, if he saw some specific questions with the associated (corrected) answers, he is able to treat correctly new, unseen (related) questions.\n",
    "\n",
    "But what does this mean in terms of Machine Learning?\n",
    "\n",
    "### Induction\n",
    "\n",
    "Take a recommender system. This system has to predict how much (on a scale) a student likes a course. The induction framework does this:\n",
    "\n",
    "1. It looks at previous years' **examples** (course student pairs) taken from the so called **training set** and **induces** a function f that will map new examples to a **predicted** rating\n",
    "2. It **evaluates** the induced function against the **test set**\n",
    "\n",
    "![induction framework](images/b9b18ab2b16b29486abb53e8c5258f47be06603bd42e1794851a237e531a5efe.png)\n",
    "\n",
    "Step 1 is contained in the red box, aka the learning algorithm. It is executed as a cycle on all the training samples. In the figure below we zoom in.\n",
    "\n",
    "![Learning algorithm](images/05b31c1af1208989ecae2cc06d88a187151eaa00f02caef5dc16af2b94e15b5b.png)\n",
    "\n",
    "\n",
    "## Formalizing\n",
    "\n",
    "### Nomenclature\n",
    "- The sample set is X and the samples are x\n",
    "- The evaluation function is f\n",
    "- The learned function is $ \\hat f $\n",
    "- The loss function is $ l(f,\\hat f) $\n",
    "- The dataset D and it's extracted from data distribution *D*\n",
    "- The expected error $ \\epsilon = \\sum [D(x,f(x))*l(f(x),\\hat f(x))] $, practically the expected value of l over distribution *D*\n",
    "### Important concepts\n",
    "- After having trained $ \\hat f(x) $, we test it, hoping that $ \\hat f(x) \\approx f(x) \\space \\forall x \\in X / D $\n",
    "  - For that reason, the test set can never be taken from the training set. It is fundamental to avoid overfitting\n",
    "- We usually differentiate every induction framework for three aspects\n",
    "   1. How we represent the function (hypothesis space)\n",
    "   2. How we evaluate the function (objective function)\n",
    "   3. How we optimize the function (loss function)\n",
    "\n",
    "### In one sentence\n",
    "Machine learning is the process of computing a function that has low expected error wrt a loss function "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
