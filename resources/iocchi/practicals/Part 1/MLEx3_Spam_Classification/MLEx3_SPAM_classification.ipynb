{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-o2cEpeQZjs"
      },
      "source": [
        "# Machine Learning - Exercise 3\n",
        "# SMS SPAM classification\n",
        "\n",
        "To perform the experiments on the SMSSpamCollection dataset you need to set-up your Colab such that it is able to load the desired data. To achieve this, you need to perform the following actions:\n",
        "\n",
        "*   download the dataset available at this [link](https://drive.google.com/a/diag.uniroma1.it/file/d/17YZemn1MidhFA0-wenfVolZAwclLRUXM/view)\n",
        "\n",
        "Then, if you are using your local runtime:\n",
        "\n",
        "*   Load the downloaded dataset in colab's runtime directory\n",
        "*   set the correct path for loading the dataset (more details will follow)\n",
        "\n",
        "while if you are using colab's resources:\n",
        "\n",
        "*   copy the dataset in a folder of your personal Drive\n",
        "*   mount your Google Drive (more details will follow)\n",
        "*   set the correct path for loading the dataset (more details will follow)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62YJE78EcK9"
      },
      "source": [
        "## Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJXZGno8QYOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb9b30e-8e44-46f6-b817-fa6d7f045b10"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print('Libraries imported.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n",
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "-mdMiii_SW2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnm5HakC6dO0"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Mount Google Drive by following the instructions given at the provided link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqhr4vhcRD39"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otk6cVVo6mR8"
      },
      "source": [
        "To load the file set the correct path of the dataset located in your drive. Once mounted, your drive works like a Linux system, so you can check folders etc... running commands like `ls` or `cd` preceded by `%`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvPjvjXGQ0sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcd5b0a-53f5-4706-dfae-7fc231e98d50"
      },
      "source": [
        "#filename = '/content/drive/My Drive/SMSSpamCollection' # Use something like this if you have your dataset in your Drive\n",
        "filename = os.getcwd() + '/SMSSpamCollection' # Use this if you are using your local runtime\n",
        "db = pd.read_csv(filename, sep='\\t', header=None, names=['label', 'text'])\n",
        "print('File loaded: %d samples.' %(len(db.label)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded: 5572 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hKbRkTh8igj_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns_oBwUo64tF"
      },
      "source": [
        "Show a random sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhl2FLCKSUmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037667e4-66a3-4ea0-c19a-8e53a1803a57"
      },
      "source": [
        "id = random.randrange(0,len(db.label))\n",
        "print('%d %s %s' %(id,db.label[id],db.text[id]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1669 ham Yes..but they said its IT.,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uBD7RsJ7bzB"
      },
      "source": [
        "## Choose vectorizer\n",
        "\n",
        "Compute vectorizer terms for all messages. More info:\n",
        "\n",
        "\n",
        "\n",
        "*   [Hashing](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html)\n",
        "*   [Count](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "*   [Tfid](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKWEucDKWnDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18edc411-e53d-4bb1-bfaf-5cfba0ec06ff"
      },
      "source": [
        "vectorizer_type = \"count\" # \"hashing\", \"count\" or \"tfid\"\n",
        "\n",
        "if vectorizer_type == \"hashing\":\n",
        "  vectorizer = HashingVectorizer(stop_words='english') # multivariate\n",
        "elif vectorizer_type == \"count\":\n",
        "  vectorizer = CountVectorizer(stop_words='english') # multinomial\n",
        "elif vectorizer_type == \"tfid\":\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "X_all = vectorizer.fit_transform(db.text)\n",
        "y_all = db.label\n",
        "\n",
        "print(X_all.shape)\n",
        "print(y_all.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 8444)\n",
            "(5572,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7oczFvA7nXb"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yw3Fz1NSu01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079a1fd9-b79c-4b7f-c530-d068d95f2f18"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all,\n",
        "          test_size=0.2, random_state=16)\n",
        "\n",
        "print(\"Train: %d - Test: %d\" %(X_train.shape[0],X_test.shape[0]))\n",
        "\n",
        "#id = random.randrange(0,X_train.shape[0])\n",
        "#print('%d ' %(id))\n",
        "#print('%d %s %s' %(id,str(y_train[id]),str(X_train[id])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 4457 - Test: 1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66oz8ep57xg"
      },
      "source": [
        "## Create and fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4BBWhpUrQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83696e9-2c20-437b-f365-5b292d011ac1"
      },
      "source": [
        "model_type = \"multinomial\" # \"bernoulli\" or \"multinomial\"\n",
        "\n",
        "if model_type == \"bernoulli\":\n",
        "  model = BernoulliNB().fit(X_train, y_train)\n",
        "  print('Bernoulli Model created')\n",
        "elif model_type == \"multinomial\":\n",
        "  model = MultinomialNB().fit(X_train, y_train)\n",
        "  print('Multinomial Model created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial Model created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VBrexa46DmE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2dR-PQtaiJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d988e40-99c4-4270-ae34-c78006da626b"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[962   9]\n",
            " [ 10 134]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       971\n",
            "        spam       0.94      0.93      0.93       144\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaiH-mlO6I-9"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD7Le-lVX9M8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eea2885-b3d2-43e8-e115-b12538970085"
      },
      "source": [
        "smsnew1 = np.array(['Hello, did you solve ML exercise?'])\n",
        "xnew1 = vectorizer.transform(smsnew1)\n",
        "ynew1 = model.predict(xnew1)\n",
        "print('%s %s' %(smsnew1,ynew1))\n",
        "\n",
        "smsnew2 = np.array(['You won $1,000! Call now 1-800-1234567'])\n",
        "xnew2 = vectorizer.transform(smsnew2)\n",
        "ynew2 = model.predict(xnew2)\n",
        "print('%s %s' %(smsnew2,ynew2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello, did you solve ML exercise?'] ['ham']\n",
            "['You won $1,000! Call now 1-800-1234567'] ['spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjYkT9M_N5Wb"
      },
      "source": [
        "## Home Exercises\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "Design and implement an evaluation procedure to assess and compare the performance of the three vectorizers and the two models proposed above.\n",
        "\n",
        "\n"
      ]
    }
  ]
}