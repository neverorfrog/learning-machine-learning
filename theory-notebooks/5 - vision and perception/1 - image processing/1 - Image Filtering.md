# Image Filtering

**What is a grayscale image?**

- It is a function $f: 2D \rightarrow \R$
- $f(x,y)$ indicates the pixel intensity in that position
- A digital image is a **discrete** version of that function
- **A colored image is just a stack of three of that functions**

**What exactly does it mean to discretize an image?**

- It means sampling and quantizing (rounding to nearest neightbor)
- The samples will be $\delta$-distant

**Types of image transformations:**

- Filtering: changes pixel values, forming a new image whose pixel values are a linear combination of the original
- Warping: changes pixel positions

## Filtering

- What do we need it for?
  - To extract features (corners, edges)
  - To enhance images (denoising, deblurring)

### Point Processing

- Each pixel is treated independently
- New image result from applying the same operation to each pixel
- Practical applications?
  - Lighten, darken, invert, contrast ecc.

### Linear shift-invariant Filtering

- What are we doing intuitively?
  - Replace each pixel by a linear combination of its neighbors
  - Each linear combination determined by the **kernel**
- We can express it mathematically as a convolution
  - Suppose we have a quadratic kernel $K$ and an image $I$
  - Convolution: $(K*I)(x,y)=\Sigma_{i,j} K(j,i) \cdot I(x-j,y-i)$
  - If the kernel is of size $(k,k)$, $i$ and $j$ will go from $-k$ to $k$ in the sum
  - In practice we flip the kernel and slide it over the image
- What are the properties of convolution?
  - It is a multiplication-like operation, so commutative, associative

#### Linear Separable Filters

- What does it mean if a filter is linearly separable?
  - The filter can be expressed as an outer product of two 1-D vectors
- Why do we need filters to be linearly separable?
  - Because convolution is computationally more efficient with them
  - It's like doing two 1-D convolutions (cost is $2*K*M*N$ where $(M,N)$ is the image size)

#### Example: Box Filter

- Constant matrix equal to 1/R if R is the number of elements in the filter
- What's its effect?
  - Blurring, because every pixel takes the mean among the surrounding pixels

#### Example: Gaussian Filter

- Filter values are sampled from a gaussian distribution
- So weights fall off with distance from center

#### Smoothing and sharpening

- TODO

## Non-linear filtering

- TODO

## Edges

- Defined as a discontinuity in the image
  - Due to depth, color, illumination ecc...
  - Practically, it's a sudden change in the intensity function, or otherwise an extremum of the derivative
- Why are edges important?
  - More compact representation than pixels
  - Semantic and shape information can be easily obtained
- **What happens when we reach the edge of the image?** $\rightarrow$ **Padding**
- But first, **how do we detected edges?**
  - Intuitively, by taking derivatives (because they are large at discontinuities)

### Edge detection with image gradients

- Definition of image gradient?
  - Vector of two images, each generated by applying a Sobel filter
  - Mathematically $\nabla f=[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}]=[S_x \otimes f,S_y \otimes f]$
    - $S_x$ is the horizontal Sobel filter and detects vertical edges
    - $S_y$ is the vertical Sobel filter and detects horizontal edges
  - The gradient points in the direction of most rapid increase in intensity
- How do we find the edge?
  - We could find edges by simply inspecting pixel intensities of the gradient, **but** noise breaks the balls
  - To solve this we blur before derivating $\rightarrow$ canny-edge detector, or derivate the blur

#### Canny-Edge Detector

- Goal is to find edges without false positives or false negatives and pinpointing edges where they actually occur
- Steps:  
  1. Filter image with derivative of the gaussian filter (or laplacian of gaussian to have higher performance)
  2. Compute magnitude and direction of gradient
  3. Non-maximum suppression, aka we eliminate pixels that may not constitute the edge by checking for every pixel if it is the maximum in its neighborhood
  4. Linking and thresholding (hysteresis), where we connect strong pixels to non-weak pixels (if they are in fact connected)
