{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-o2cEpeQZjs"
      },
      "source": [
        "# Machine Learning - Exercise 3\n",
        "# SMS SPAM classification\n",
        "\n",
        "To perform the experiments on the SMSSpamCollection dataset you need to set-up your Colab such that it is able to load the desired data. To achieve this, you need to perform the following actions:\n",
        "\n",
        "*   download the dataset available at this [link](https://drive.google.com/a/diag.uniroma1.it/file/d/17YZemn1MidhFA0-wenfVolZAwclLRUXM/view)\n",
        "*   copy the dataset in a folder of your personal Drive\n",
        "*   mount your Google Drive (more details will follow)\n",
        "*   set the correct path for loading the dataset (more details will follow)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62YJE78EcK9"
      },
      "source": [
        "## Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJXZGno8QYOn",
        "outputId": "9821411e-e2e4-4be4-e1b2-fc0894b6a346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print('Libraries imported.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnm5HakC6dO0"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Mount Google Drive by following the instructions given at the provided link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqhr4vhcRD39",
        "outputId": "a7c93717-4357-4669-cd9f-8edd9cbc3083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otk6cVVo6mR8"
      },
      "source": [
        "To load the file set the correct path of the dataset located in your drive. Once mounted, your drive works like a Linux system, so you can check folders etc... running commands like `ls` or `cd` preceded by `%`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvPjvjXGQ0sw",
        "outputId": "cf4e5641-d022-4282-efbe-2703293d9d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File loaded: 5572 samples.\n"
          ]
        }
      ],
      "source": [
        "# example path of dataset copied in My Drive folder: /content/drive/My Drive/SMSSpamCollection'\n",
        "filename = 'SMSSpamCollection'\n",
        "db = pd.read_csv(filename, sep='\\t', header=None, names=['label', 'text'])\n",
        "print('File loaded: %d samples.' %(len(db.label)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns_oBwUo64tF"
      },
      "source": [
        "Show a random sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhl2FLCKSUmo",
        "outputId": "fb7d2c28-e4f7-4ec3-a2a2-287bfc779bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "727 ham Of cos can lar i'm not so ba dao ok... 1 pm lor... Y u never ask where we go ah... I said u would ask on fri but he said u will ask today...\n"
          ]
        }
      ],
      "source": [
        "id = random.randrange(0,len(db.label))\n",
        "print('%d %s %s' %(id,db.label[id],db.text[id]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uBD7RsJ7bzB"
      },
      "source": [
        "## Choose vectorizer\n",
        "\n",
        "Compute vectorizer terms for all messages. More info:\n",
        "\n",
        "\n",
        "\n",
        "*   [Hashing](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html)\n",
        "*   [Count](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "*   [Tfid](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKWEucDKWnDY",
        "outputId": "13d30405-0c46-43ef-e752-ce310f6556e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5572, 8444)\n",
            "(5572,)\n"
          ]
        }
      ],
      "source": [
        "vectorizer_type = \"count\" # \"hashing\", \"count\" or \"tfid\"\n",
        "\n",
        "if vectorizer_type == \"hashing\":\n",
        "  vectorizer = HashingVectorizer(stop_words='english') # multivariate\n",
        "elif vectorizer_type == \"count\":\n",
        "  vectorizer = CountVectorizer(stop_words='english') # multinomial\n",
        "elif vectorizer_type == \"tfid\":\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "X_all = vectorizer.fit_transform(db.text) #transform the document into a vector of numbers\n",
        "y_all = db.label\n",
        "\n",
        "print(X_all.shape)\n",
        "print(y_all.shape)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7oczFvA7nXb"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yw3Fz1NSu01",
        "outputId": "f5337cd5-7afa-4671-d8b5-958d639ff8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 4457 - Test: 1115\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "          test_size=0.2, random_state=16)\n",
        "\n",
        "print(\"Train: %d - Test: %d\" %(X_train.shape[0],X_test.shape[0]))\n",
        "\n",
        "#id = random.randrange(0,X_train.shape[0])\n",
        "#print('%d ' %(id))\n",
        "#print('%d %s %s' %(id,str(y_train[id]),str(X_train[id])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y66oz8ep57xg"
      },
      "source": [
        "## Create and fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk4BBWhpUrQO",
        "outputId": "3cfc13d0-8bc4-475e-d062-06abb82220bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Model created\n"
          ]
        }
      ],
      "source": [
        "model_type = \"multinomial\" # \"bernoulli\" or \"multinomial\"\n",
        "\n",
        "if model_type == \"bernoulli\":\n",
        "  model = BernoulliNB().fit(X_train, y_train)\n",
        "  print('Bernoulli Model created')\n",
        "elif model_type == \"multinomial\":\n",
        "  model = MultinomialNB().fit(X_train, y_train)\n",
        "  print('Multinomial Model created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VBrexa46DmE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2dR-PQtaiJC",
        "outputId": "c49e2f03-dca3-4bdc-b1a3-1b309c7c1f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[962   9]\n",
            " [ 10 134]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99       971\n",
            "        spam       0.94      0.93      0.93       144\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.96      0.96      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaiH-mlO6I-9"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD7Le-lVX9M8",
        "outputId": "8a13f765-f74a-4097-bbf9-a37f424ef4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Hello, did you solve ML exercise?'] ['ham']\n",
            "['You won $1,000! Call now 1-800-1234567'] ['spam']\n"
          ]
        }
      ],
      "source": [
        "smsnew1 = np.array(['Hello, did you solve ML exercise?'])\n",
        "xnew1 = vectorizer.transform(smsnew1)\n",
        "ynew1 = model.predict(xnew1)\n",
        "print('%s %s' %(smsnew1,ynew1))\n",
        "\n",
        "smsnew2 = np.array(['You won $1,000! Call now 1-800-1234567'])\n",
        "xnew2 = vectorizer.transform(smsnew2)\n",
        "ynew2 = model.predict(xnew2)\n",
        "print('%s %s' %(smsnew2,ynew2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjYkT9M_N5Wb"
      },
      "source": [
        "## Home Exercises\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "Design and implement an evaluation procedure to assess and compare the performance of the three vectorizers and the two models proposed above.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
