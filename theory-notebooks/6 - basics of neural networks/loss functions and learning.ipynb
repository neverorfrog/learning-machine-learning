{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe for constructing loss functions\n",
    "\n",
    "1) Choose a parametrized probability distribution over the outputs $P(y|x;\\phi)$ $\\rightarrow$ Likelihood Function\n",
    "    - The network computes $\\phi = f[x,\\theta]$ where $\\theta$ are network weights and biases\n",
    "    - In general expressed as $L(\\theta ; x, y) = \\prod_i l(\\theta;x_i,y_i) = \\prod_i P(y_i|x_i;\\theta)$ (all data samples are iid)\n",
    "    - When $y$ are data labels the likelihood indicates how well the output probability distribution represents the data\n",
    "2) Find the network parameters $\\hat\\theta$ that maximise the likelihood function $\\rightarrow$ Maximum Likelihood Estimate\n",
    "    - **Loss function** encourages each label to have high probability under the computed distribution, given the corresponding training input\n",
    "    - In practive we take log of L, obtaining a sum of logs and minimize its negation, obtaining **NLL** loss function\n",
    "    - $\\hat \\theta = \\argmin_{\\theta} (-\\sum_i \\log[P(y_i|x_i;\\theta)]) = \\argmin_{\\theta} (J(\\theta))$\n",
    "    - That we achieve with stochastic gradient descent\n",
    "3) For inference, we return either the whole distribution $P(y|x;\\phi)$ or a point estimate taking the maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "- Univariate Regression\n",
    "    - Goal : predict a single scalar output based on some features\n",
    "    - Likelihood : gaussian with mean computed by the network $\\rightarrow$ $L(\\theta;x,y) \\propto \\prod_i exp (-(y_i - \\theta^T x_i)^2) $\n",
    "    - Loss Function : negative log of L $\\rightarrow$ $J(\\theta) \\propto - \\sum_i \\log (exp (-(y_i - \\theta^T x_i)^2))$\n",
    "        - Finally $J(\\theta) = \\sum_i (y_i - \\theta^T x_i)^2$\n",
    "\n",
    "- Binary Classification\n",
    "    - Goal : predict 0 or 1 based on some features\n",
    "    - Likelihood : probability mass function of the Bernoulli distribution \n",
    "        - $L(\\theta;x,y) = \\prod_i ([P(y_i=1|x_i)]^{y_i} \\times [1-P(y_i=1|x)]^{1-y_i})$\n",
    "        - Intuitively, probability of observing as outcome of a bernoulli trial label 0 or 1 when observing a data point4\n",
    "        - $P(y=1|x) = \\sigma(\\theta^T x)$ where $\\sigma$ is the sigmoid function\n",
    "    - Loss Function : $J(\\theta) = -log(P(y|x;\\theta))$\n",
    "\n",
    "- Multiclass Classification\n",
    "    - Goal : predict correct class among k\n",
    "    - Likelihood : probability mass function of the categorical distribution \n",
    "        - $L(\\theta;x,y) = softmax_k(f[x,\\theta])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss\n",
    "- Measures dissimilarity between empirical (sample) distribution and real distribution\n",
    "- Can be interpreted as maximizing the probability of the true class at the expense\n",
    "of all other outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation (Core of SGD)\n",
    "\n",
    "## Intuition on derivatives\n",
    "- $ w \\uparrow \\epsilon $ (w increases of $\\epsilon$) causes $J(w) \\uparrow k\\epsilon$ $\\implies$ $\\frac{\\partial J}{\\partial w} = k$\n",
    "- Small derivative means small change in $w$\n",
    "  - In fact in this case, changing $w$ doesn't change that much J\n",
    "- The derivative on each variable tells you the sensitivity of the whole expression on its value.\n",
    "\n",
    "## Computational graph\n",
    "- When we do a forward propagation, we have to compute the gradient in order to optimize\n",
    "- That is achieved by doing backprop, which means unwinding the prediction by doing chained derivatives\n",
    "\n",
    "![picture 0](images/backprop.png)  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
