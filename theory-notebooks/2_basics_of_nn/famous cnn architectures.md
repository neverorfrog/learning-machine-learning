# Famous CNN Architectures

## LeNet

- Most basic one
- Just convolutional, pooling and sigmoid

## AlexNet

- Exploits the concept of hierarchical features
- Exploits deeper architecture
- Introduces normalization layers
- Uses relu instead of sigmoid

## VGGNet

- Modular architecture
- Found that deep and narrow outperforms shallow and wide
- One module is made of
  - 3x3 kernel with padding 1
  - relu activation
  - 2x2 pooling kernel
- Exploited parallel GPUs

## GoogLeNet

- Uses inception blocks (parallel convolutions)
- Avoids fully connected layers


